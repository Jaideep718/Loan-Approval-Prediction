{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b21f169",
   "metadata": {},
   "source": [
    "## PREPROCESSING AND DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cc4b3",
   "metadata": {},
   "source": [
    "**Import the Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996e0799",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd273a",
   "metadata": {},
   "source": [
    "**Load the Train and Test Datasets and store them as dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5810eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training dataset\n",
    "df=pd.read_csv(\"training_set.csv\")\n",
    "# Loading the testing dataset\n",
    "dt=pd.read_csv(\"testing_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe24be8",
   "metadata": {},
   "source": [
    "**Analysing the Train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ce40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5348a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d53eb",
   "metadata": {},
   "source": [
    "**Analysing the Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef2c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0660816",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935a1fd",
   "metadata": {},
   "source": [
    "**Checking the null values in train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249717b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2a3d0",
   "metadata": {},
   "source": [
    "**Checking the null values in test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5746d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db093014",
   "metadata": {},
   "source": [
    "**Visualising the missing values in train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the missing values\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "sns.heatmap(df.isnull(),cbar=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7b19c",
   "metadata": {},
   "source": [
    "**Visualising the missing values in test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the missing values\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "sns.heatmap(dt.isnull(),cbar=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc8613",
   "metadata": {},
   "source": [
    "**Dropping the column 'Loan ID' in both the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns='Loan_ID')\n",
    "dt=dt.drop(columns='Loan_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509891c",
   "metadata": {},
   "source": [
    "**Dividing the columns into categorical and numeric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf25c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data for train data (includes the column Loan_Status)\n",
    "categorical_data = [i for i in df.columns if df[i].nunique()<=4]\n",
    "categorical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b73f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data for test data (excludes the column Loan_Status)\n",
    "categorical_data_dt=['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed','property_Area']\n",
    "categorical_data_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical data\n",
    "numerical_data = [i for i in df.columns if i not in categorical_data]\n",
    "numerical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9a64b",
   "metadata": {},
   "source": [
    "**Understanding average values for all the numerical columns for each loan status category in the train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff216320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average applicant income for each loan status category\n",
    "app_inc = df.groupby(['Loan_Status'])['ApplicantIncome'].mean().reset_index()\n",
    "app_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca629e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average coapplicant income for each loan status category\n",
    "coapp_inc = df.groupby(['Loan_Status'])['CoapplicantIncome'].mean().reset_index()\n",
    "coapp_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average loan amount for each loan status category\n",
    "loan_amt = df.groupby(['Loan_Status'])['LoanAmount'].mean().reset_index()\n",
    "loan_amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7aaf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average loan amount term for each loan status category\n",
    "loan_amt_term = df.groupby(['Loan_Status'])['Loan_Amount_Term'].mean().reset_index()\n",
    "loan_amt_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb4efa3",
   "metadata": {},
   "source": [
    "**Distribution of Numerical Features in the Train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms to represent the all numerical features\n",
    "df[numerical_data].hist(figsize=(15, 12), bins=20, edgecolor='black')\n",
    "plt.suptitle('Distribution of Numerical Features in the Dataset', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1289f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distplots to represent numerical columns\n",
    "plt.figure(figsize=(15,10))\n",
    "for n, col in enumerate(numerical_data[:]):\n",
    "  plt.subplot(4, 2, n+1)  # 4 rows, 2 columns\n",
    "  sns.distplot(df[col])\n",
    "  plt.title(col.title())\n",
    "  plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8a997",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "* ApplicantIncome - Highly right-skewed, most applicants have income below ₹10,000. A few applicants have extremely high incomes, which may be outliers.\n",
    "* CoapplicantIncome - Right-skewed, many co-applicants have zero or very low income. This may imply they are not earning or not included in income consideration.\n",
    "* LoanAmount - Slight right skew, but more balanced. Majority of loans are between ₹100,000–₹200,000. There are some large loan amounts that stretch the distribution.\n",
    "* Loan_Amount_Term - Discrete distributions showing limited choices. Most loans are for 360 months (30 years). There are fewer shorter terms like 120, 180, or 240 months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ef503",
   "metadata": {},
   "source": [
    "**Distribution of Categorical Features in the Train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b619b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the colours to use\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "\n",
    "# Creating a figure with 8 subplots (4 rows, 2 columns)\n",
    "fig, axs = plt.subplots(4, 2, figsize=(14, 20))  # 4 rows, 2 columns\n",
    "\n",
    "# Plot 1: Loan_Status\n",
    "ax = axs[0, 0]\n",
    "df['Loan_Status'].value_counts().plot.bar(ax=ax, color=colors)\n",
    "ax.set_title('Loan_Status')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# Plot 2: Gender\n",
    "ax = axs[0, 1]\n",
    "df['Gender'].value_counts().plot.bar(ax=ax, color=colors)\n",
    "ax.set_title('Gender')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# Plot 3: Married\n",
    "ax = axs[1, 0]\n",
    "df['Married'].value_counts().plot.bar(ax=ax, color=colors)\n",
    "ax.set_title('Married')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# Plot 4: Self_Employed\n",
    "ax = axs[1, 1]\n",
    "df['Self_Employed'].value_counts().plot.bar(ax=ax, color=colors)\n",
    "ax.set_title('Self_Employed')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# Plot 5: Credit_History\n",
    "ax = axs[2, 0]\n",
    "df['Credit_History'].value_counts().plot.bar(ax=ax, color=colors)\n",
    "ax.set_title('Credit_History')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# Plot 6: Education\n",
    "ax = axs[2, 1]\n",
    "df['Education'].value_counts().plot.bar(ax=ax, color=colors)\n",
    "ax.set_title('Education')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# Plot 7: Dependents\n",
    "ax = axs[3, 0]\n",
    "df['Dependents'].value_counts().plot.bar(ax=ax, color=colors)\n",
    "ax.set_title('Dependents')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# Plot 8: property_Area\n",
    "ax = axs[3, 1]\n",
    "df['property_Area'].value_counts().plot.bar(ax=ax, color=colors)\n",
    "ax.set_title('property_Area')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                ha='center', va='bottom')\n",
    "# Displaying the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d7e491",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "* Loan_Status - Has 422 entries with loan approved as 'Y' and 192 entries as 'N'\n",
    "* Gender - Has 487 entries with gender as 'Male' and 112 entries as 'Female'\n",
    "* Married - Has 398 entries with loan married as 'Yes' and 213 entries as 'No'\n",
    "* Self_Employed - Has 500 entries with self employed as 'Yes' and 82 entries as 'No'\n",
    "* Credit_History - Has 475 entries with credit history as '1.0' and 89 entries as '0.0'\n",
    "* Education - Has 479 entries with education as 'Graduate' and 134 entries as 'Not Graduate'\n",
    "* Dependents - Has 345 entries with dependents as '0', 102 entries as '1', 101 entries as '2' and 51 entries as '3+'\n",
    "* property_Area - Has 233 entries with property area as 'Semiurban', 202 entries as 'Urban' and 179 entries as 'Rural'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b7732",
   "metadata": {},
   "source": [
    "**Bivariate analysis between different categorical features and Loan_Status in the train dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c9bae",
   "metadata": {},
   "source": [
    "Each graph shows the breakdown of Loan_Status for each of the categorical variables, helping to identify trends or patterns based on the categorical features. The bars represent the count of applicants in each category, and the numbers on top of the bars show the exact counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_data:\n",
    "    if col != 'Loan_Status':  # Skip Loan_Status column\n",
    "        cross_tab = pd.crosstab(df[col], df['Loan_Status'])\n",
    "\n",
    "        # Plot side-by-side bars (not stacked)\n",
    "        ax = cross_tab.plot(kind='bar', stacked=False, figsize=(7, 5), color=['orange', 'blue'])\n",
    "\n",
    "        plt.title(f'Loan Status by {col}')\n",
    "        plt.ylabel('Count')\n",
    "        plt.ylim(0, cross_tab.values.max() + 20)\n",
    "\n",
    "        # Add value labels on top of each bar\n",
    "        for p in ax.patches:\n",
    "            height = p.get_height()\n",
    "            if height > 0:\n",
    "                ax.text(\n",
    "                    p.get_x() + p.get_width() / 2., \n",
    "                    height + 1, \n",
    "                    f'{int(height)}', \n",
    "                    ha='center', va='bottom', fontsize=9\n",
    "                )\n",
    "\n",
    "        plt.legend(title='Loan Status')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15f973",
   "metadata": {},
   "source": [
    "**Converting Categorical Data to Numeric Codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a05f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data in train dataset\n",
    "for col in categorical_data:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "df.replace(-1, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21541a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data in train dataset\n",
    "for col in categorical_data_dt:\n",
    "    dt[col] = dt[col].astype('category').cat.codes\n",
    "dt.replace(-1, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9dba4",
   "metadata": {},
   "source": [
    "**Bivariate analysis between different numerical features and Loan_Status in the train dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e720f75",
   "metadata": {},
   "source": [
    "The regression plots display how each numerical feature correlates with the Loan_Status. Since Loan_Status is binary (1 for loan approval and 0 for loan denial), the graphs reveal loan approval probability trends(increase or decrease) and presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f77bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.suptitle('Numerical Features Data Analysis with Loan_Status', fontsize=21, fontweight='bold', y=1.03)\n",
    "\n",
    "for i,col in enumerate(numerical_data):\n",
    "  plt.subplot(2, 4, i+1) # Subplots of 2 rows and 4 columns\n",
    "\n",
    "  # Regression plots\n",
    "  sns.regplot(x=df[col], y='Loan_Status', data=df)\n",
    "  \n",
    "  plt.xlabel(col)\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68425664",
   "metadata": {},
   "source": [
    "**Pairplots between all the Numerical Features in the train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PairPlot\n",
    "sns.pairplot(df[numerical_data + ['Loan_Status']], hue='Loan_Status', palette='husl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b2f58",
   "metadata": {},
   "source": [
    "**Correlation between all the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation\n",
    "plt.figure(figsize = (12,10))\n",
    "corr = df.corr()\n",
    "sns.heatmap(abs(corr), annot=True, cmap = 'flare')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10df99",
   "metadata": {},
   "source": [
    "**Correlation of all the features with Loan_Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f2f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of all features with 'Loan_Status' and sort them in descending order\n",
    "loan_status_corr = corr['Loan_Status'].sort_values(ascending=False)\n",
    "loan_status_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf79365",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610dc565",
   "metadata": {},
   "source": [
    "**Filling null values in categorical columns with most frequent observation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065562af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the null values of categorical columns in train dataset\n",
    "for col in categorical_data:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "#Filling the null values in test dataset\n",
    "for col in categorical_data_dt:\n",
    "    dt[col].fillna(dt[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29becb5",
   "metadata": {},
   "source": [
    "**Filling null values in numerical columns with the median value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649be76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the null values of numerical columns in train dataset\n",
    "for col in numerical_data:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "#Filling the null values of numerical columns in test dataset\n",
    "for col in numerical_data:\n",
    "    dt[col].fillna(dt[col].median(), inplace=True)\n",
    "\n",
    "#Filling in Credit_History with most frequent observation only in test data (can't be a median value) as it was encoded for in train data\n",
    "dt['Credit_History'].fillna(dt['Credit_History'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3bbf1d",
   "metadata": {},
   "source": [
    "**Checking for null values in train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b956ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69ea2b",
   "metadata": {},
   "source": [
    "**Checking for null values in test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aede8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed22df",
   "metadata": {},
   "source": [
    "**Checking for outliers in train data using boxplots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d298ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR and detect outliers for each column\n",
    "outlier_counts = {}\n",
    "\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Count outliers\n",
    "    outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
    "    outlier_counts[col] = outliers\n",
    "\n",
    "# Plot the boxplot\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.boxplot(data=df)\n",
    "plt.title('Boxplot of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# Print the number of outliers for each column\n",
    "print(\"Number of outliers for each column:\")\n",
    "for col, count in outlier_counts.items():\n",
    "    print(f\"{col}: {count} outliers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c483390",
   "metadata": {},
   "source": [
    "**Individual Boxplots for numerical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for numerical data\n",
    "for col in numerical_data:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(y=df[col], color='skyblue')\n",
    "    plt.title(f'Boxplot for {col}', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e967bd5",
   "metadata": {},
   "source": [
    "**Dealing with outliers in numerical data by capping**:  Replacing values lower than the 10th percentile with the 10th percentile value and higher than the 90th percentile with the 90th percentile value, effectively removing extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3093c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(df, col, lower_quantile=0.1, upper_quantile=0.9):\n",
    "    lower_bound = df[col].quantile(lower_quantile)\n",
    "    upper_bound = df[col].quantile(upper_quantile)\n",
    "    \n",
    "    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    return df\n",
    "for col in numerical_data:\n",
    "     df = cap_outliers(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66346468",
   "metadata": {},
   "source": [
    "**Outliers after capping for numerical data in train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the number of outliers for each numerical column\n",
    "def count_outliers(df, col):\n",
    "    # Define lower and upper bounds for outliers\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1  # Interquartile Range\n",
    "    lower_bound = Q1 - 1.5 * IQR  # Lower bound\n",
    "    upper_bound = Q3 + 1.5 * IQR  # Upper bound\n",
    "\n",
    "    # Count the number of outliers (values outside the lower and upper bounds)\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    return len(outliers)\n",
    "\n",
    "# Calculate outliers for each numerical column\n",
    "print(\"Number of outliers for each numerical column:\")\n",
    "for col in numerical_data:\n",
    "    outlier_count = count_outliers(df, col)\n",
    "    print(f\"{col}: {outlier_count} outliers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f40233",
   "metadata": {},
   "source": [
    "Outliers still present in Loan_Amount_Term as it is not an evenly distributed data having most of its entries as distinct values like 360 folowed by 240,180,etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f50ce73",
   "metadata": {},
   "source": [
    "**Boxplots after capping the outliers of numerical data in train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a129ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for numerical data\n",
    "for col in numerical_data:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(y=df[col], color='skyblue')\n",
    "    plt.title(f'Boxplot for {col}', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e0a53",
   "metadata": {},
   "source": [
    "**Handling rear categories so as to avoid issues caused by too many unique values with low frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675944b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for category frequency (e.g., 5% of the data)\n",
    "threshold = 0.05\n",
    "for col in categorical_data:\n",
    "    category_counts = df[col].value_counts(normalize=True)  # Calculate frequency distribution\n",
    "    rare_categories = category_counts[category_counts < threshold].index  # Find rare categories\n",
    "    \n",
    "    # Replace rare categories with 'Other'\n",
    "    df[col] = df[col].replace(rare_categories, 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189bc6fb",
   "metadata": {},
   "source": [
    "**Analysing the dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2087bc0",
   "metadata": {},
   "source": [
    "Here, all the categorical columns have been encoded. The column 'property_Area' has values 0,1 and 2. One hot encoding is performed on this to form columns - Urban, Semiurban and Rural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61978423",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e87846",
   "metadata": {},
   "source": [
    "**One hot encoding on train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222fde73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['property_Area_str'] = df['property_Area'].map({0: 'Urban', 1: 'Rural', 2: 'Semiurban'})\n",
    "\n",
    "# One-hot encode the string versions, keep original, and convert True/False to int\n",
    "df_ohe = pd.get_dummies(df[['property_Area_str']], prefix=['property_Area'])\n",
    "df_ohe = df_ohe.astype(int)  # Convert True/False to 1/0\n",
    "\n",
    "# Join the one-hot encoded columns back\n",
    "df = pd.concat([df, df_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53601694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00be821",
   "metadata": {},
   "source": [
    "**One hot encoding on test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a5a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['property_Area_str'] = dt['property_Area'].map({0: 'Urban', 1: 'Rural', 2: 'Semiurban'})\n",
    "\n",
    "dt_ohe = pd.get_dummies(dt[['property_Area_str']], prefix=['property_Area'])\n",
    "dt_ohe = dt_ohe.astype(int)\n",
    "\n",
    "dt = pd.concat([dt, dt_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537669b3",
   "metadata": {},
   "source": [
    "**Removing the str columns from the train and test dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f47229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[\"property_Area_str\"])\n",
    "dt=dt.drop(columns=[\"property_Area_str\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8e5a0",
   "metadata": {},
   "source": [
    "**Computing correlation between all features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=df.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='rocket', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of All Numeric Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85069c96",
   "metadata": {},
   "source": [
    "**Computing correlation between the target Loan_Status and all columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_status_corr = corr_matrix['Loan_Status'].sort_values(ascending=False)\n",
    "loan_status_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ea515",
   "metadata": {},
   "source": [
    "**Removing 'property_Area' col from both train and test dataset as it has negligible correlation(lesser than its one hot encoded columns)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97313a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[\"property_Area\"])\n",
    "dt=dt.drop(columns=[\"property_Area\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f02ec4",
   "metadata": {},
   "source": [
    "**Adding new features like Total Income, Loan to Income Ratio, EMI and Balance Income to both the train and test dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering on train dataframe\n",
    "df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
    "df['Loan_Income_Ratio'] = df['LoanAmount'] / df['Total_Income']\n",
    "df['EMI'] = df['LoanAmount'] / df['Loan_Amount_Term']\n",
    "df['Balance_Income'] = df['Total_Income'] - df['EMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513135d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering on test dataframe\n",
    "dt['Total_Income'] = dt['ApplicantIncome'] + dt['CoapplicantIncome']\n",
    "dt['Loan_Income_Ratio'] = dt['LoanAmount'] / dt['Total_Income']\n",
    "dt['EMI'] = dt['LoanAmount'] / dt['Loan_Amount_Term']\n",
    "dt['Balance_Income'] = dt['Total_Income'] - dt['EMI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a6235",
   "metadata": {},
   "source": [
    "**Correlation calculation after adding new columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42449de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=df.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='rocket', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of All Numeric Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd018e7",
   "metadata": {},
   "source": [
    "**Correlation of all columns with Loan_Status after adding new columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_status_corr = corr_matrix['Loan_Status'].sort_values(ascending=False)\n",
    "loan_status_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3acc98f",
   "metadata": {},
   "source": [
    "**Saving the preprocessed train and test datframes to csv files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7945cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataframe saved as 'training_preprocessed.csv'\n",
    "df.to_csv('training_preprocessed.csv', index=False)\n",
    "\n",
    "# Train dataframe saved as 'testing_preprocessed.csv'\n",
    "dt.to_csv('testing_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a539075",
   "metadata": {},
   "source": [
    "## *CLASSIFICATION*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4dfb65",
   "metadata": {},
   "source": [
    "**Looading the preprocessed train and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl=pd.read_csv('training_preprocessed.csv')\n",
    "dt_cl=pd.read_csv('testing_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7185f7",
   "metadata": {},
   "source": [
    "**Splitting the train data into training and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl_train,df_cl_val=train_test_split(df_cl,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba91257",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cl_train=df_cl_train[\"Loan_Status\"]\n",
    "x_cl_train=df_cl_train.drop(columns=\"Loan_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8503a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cl_val=df_cl_val[\"Loan_Status\"]\n",
    "x_cl_val=df_cl_val.drop(columns=\"Loan_Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8894acd0",
   "metadata": {},
   "source": [
    "## Model - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6837ba",
   "metadata": {},
   "source": [
    "**Import the necessary modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b337a2",
   "metadata": {},
   "source": [
    "**Training the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=80, random_state=42)\n",
    "rf.fit(x_cl_train, y_cl_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d555f",
   "metadata": {},
   "source": [
    "**Making predictions on the validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f7702",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cl_val_pred = rf.predict(x_cl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc66a0",
   "metadata": {},
   "source": [
    "**Metrics for the evaluation of the model performance on validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37cdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_cl_val, y_cl_val_pred)\n",
    "acc = accuracy_score(y_cl_val, y_cl_val_pred)\n",
    "precision = precision_score(y_cl_val, y_cl_val_pred)\n",
    "recall = recall_score(y_cl_val, y_cl_val_pred)\n",
    "f1 = f1_score(y_cl_val, y_cl_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "print(\"Confusion Matrix:\")\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b22890",
   "metadata": {},
   "source": [
    "**Making predictions on test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cl_test_pred = rf.predict(dt_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b992d",
   "metadata": {},
   "source": [
    "**Printing the Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a791db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cl_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7c320",
   "metadata": {},
   "source": [
    "**Saving the classification predictions to a new submissions csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baed44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding predictions as a new column\n",
    "dt_cl['Loan_Status'] = y_cl_test_pred\n",
    "\n",
    "#Saving to a new CSV file\n",
    "dt_cl.to_csv('final_submission_classification.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319dfc2b",
   "metadata": {},
   "source": [
    "## *REGRESSION TASK 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3a3d0",
   "metadata": {},
   "source": [
    "**Loading the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rg1=pd.read_csv(\"training_preprocessed.csv\")\n",
    "dt_rg1=pd.read_csv(\"final_submission_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d23c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_rg1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6172e",
   "metadata": {},
   "source": [
    "**Splitting the train data into training and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db098701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rg1_train,df_rg1_val=train_test_split(df_rg1,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rg1_train = df_rg1_train[df_rg1_train['Loan_Status']==1]['LoanAmount']\n",
    "x_rg1_train = df_rg1_train[df_rg1_train['Loan_Status']==1].drop(columns=['LoanAmount','Loan_Status'])\n",
    "\n",
    "y_rg1_val = df_rg1_val[df_rg1_val['Loan_Status']==1]['LoanAmount']\n",
    "x_rg1_val = df_rg1_val[df_rg1_val['Loan_Status']==1].drop(columns=['LoanAmount','Loan_Status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1de012d",
   "metadata": {},
   "source": [
    "## Model - Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd95414",
   "metadata": {},
   "source": [
    "**Import the necessary modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3453406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3679a7c6",
   "metadata": {},
   "source": [
    "**Train the model on the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7086747",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_rg1_train, y_rg1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d42e31",
   "metadata": {},
   "source": [
    "**Predictions on validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5da2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_rg1_predict = model.predict(x_rg1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebeed12",
   "metadata": {},
   "source": [
    "**Metrics for evaluation of predictions made on validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd81ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(y_rg1_val, y_val_rg1_predict))\n",
    "mae = mean_absolute_error(y_rg1_val, y_val_rg1_predict)\n",
    "r2 = r2_score(y_rg1_val, y_val_rg1_predict)\n",
    "mean_value = y_rg1_val.mean()\n",
    "rmse_percentage = (rmse / mean_value) * 100\n",
    "\n",
    "print(f'RMSE: {rmse:.3f}')\n",
    "print(f'MAE: {mae:.3f}')\n",
    "print(f'R2: {r2:.3f}')\n",
    "print(f'RMSE (percentage): {rmse_percentage:.2f}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e935eb",
   "metadata": {},
   "source": [
    "**Predictions on the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc477c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_y_rg1 = dt_rg1[dt_rg1['Loan_Status']==0]['LoanAmount']\n",
    "dt_x_rg1 = dt_rg1[dt_rg1['Loan_Status']==0].drop(columns=['LoanAmount','Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rg1_predict = model.predict(dt_x_rg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27678ba6",
   "metadata": {},
   "source": [
    "**Printing the Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rg1_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b5e1f",
   "metadata": {},
   "source": [
    "**Saving the predictions to a new submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ec2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding predictions as a new column\n",
    "dt_x_rg1['LoanAmount'] = y_test_rg1_predict\n",
    "\n",
    "#Saving to a new CSV file\n",
    "dt_x_rg1.to_csv('final_submission_regression1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f73b20",
   "metadata": {},
   "source": [
    "## *REGRESSION TASK 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6c937",
   "metadata": {},
   "source": [
    "**Loading the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rg2=pd.read_csv(\"training_preprocessed.csv\")\n",
    "dt_rg2=pd.read_csv(\"final_submission_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rg2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40576e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_rg2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823fe3bc",
   "metadata": {},
   "source": [
    "**Splitting the data into training and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rg2_train,df_rg2_val=train_test_split(df_rg2,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rg2_train = df_rg2_train[(df_rg2_train['Loan_Status']==1)]['Loan_Amount_Term']\n",
    "x_rg2_train = df_rg2_train[(df_rg2_train['Loan_Status']==1)].drop(columns=['Loan_Amount_Term','Loan_Status'])\n",
    "\n",
    "y_rg2_val = df_rg2_val[(df_rg2_val['Loan_Status'] == 1) & (df_rg2_val['Loan_Amount_Term'] > 240)]['Loan_Amount_Term']\n",
    "x_rg2_val = df_rg2_val[(df_rg2_val['Loan_Status'] == 1) & (df_rg2_val['Loan_Amount_Term'] > 240)].drop(columns=['Loan_Amount_Term', 'Loan_Status'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a53ce9",
   "metadata": {},
   "source": [
    "## Model - Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7482a5",
   "metadata": {},
   "source": [
    "**Import the necessary module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46345714",
   "metadata": {},
   "source": [
    "**Train the model on the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(x_rg2_train, y_rg2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6608e0d",
   "metadata": {},
   "source": [
    "**Make predictions on validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_rg2_predict = gb.predict(x_rg2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d72ee",
   "metadata": {},
   "source": [
    "**Metrics for evaluaion of the model performance on the validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(y_rg2_val, y_val_rg2_predict))\n",
    "mae = mean_absolute_error(y_rg2_val, y_val_rg2_predict)\n",
    "r2 = r2_score(y_rg2_val, y_val_rg2_predict)\n",
    "mean_value = y_rg2_val.mean()\n",
    "rmse_percentage = (rmse / mean_value) * 100\n",
    "\n",
    "print(f'RMSE: {rmse:.3f}')\n",
    "print(f'MAE: {mae:.3f}')\n",
    "print(f'R2: {r2:.3f}')\n",
    "print(f'RMSE (percentage): {rmse_percentage:.2f}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d1f13",
   "metadata": {},
   "source": [
    "**Predictions on the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rg2_test = dt_rg2[(dt_rg2['Loan_Status'] == 0) & (dt_rg2['Loan_Amount_Term'] < 240)]['Loan_Amount_Term']\n",
    "x_rg2_test = dt_rg2[(dt_rg2['Loan_Status'] == 0) & (dt_rg2['Loan_Amount_Term'] < 240)].drop(columns=['Loan_Amount_Term', 'Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c2444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rg2_predict = gb.predict(x_rg2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b904b",
   "metadata": {},
   "source": [
    "**Printing the predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794102b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rg2_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e4b6e",
   "metadata": {},
   "source": [
    "**Saving the predictions to a new submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c92400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding predictions as a new column\n",
    "x_rg2_test['Loan_Amount_Term'] = y_test_rg2_predict\n",
    "\n",
    "#Saving to a new CSV file\n",
    "x_rg2_test.to_csv('final_submission_regression2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
